---
title: "Simulate from maximum likelihood parameter estimates"
author: Sylvia Ranjeva
date: May 6, 2020
output: html_document
---
Code to simulate interventions based on scaling of post-intervention beta beginning 5/1/2020 at increases of 20, 40, and 60% transmission rate. 

First, set up the code and specify the parameters for the forecasting:
```{r}
require(dplyr)
require(pomp)
require(ggplot2)
require(magrittr)
require(lubridate)
require(MASS)
require(reshape2)
require(dplyr)
require(cowplot)
require(scales)
require(MMWRweek)
require(rmutil)
library(tidyverse)

select <- dplyr::select
rename <- dplyr::rename
summarize <- dplyr::summarise
contains <- dplyr::contains

root <- '../'
source(file.path(root, '_covid_root.R'))

covid_set_root(root)

input_points_file ="latest_fit_results/consolidated.all.sample_from_surface.csv"
source("input_file_specification.R") # script to read in necessary files

# Projection specifications: all projections
reference_date <- as.Date("2020-01-14") # All numeric times in reference to this date 
end_projection_date <- as.Date("2020-10-01")
end_forecast_hub_date <- as.Date("2020-06-20")
start_projection_date <- as.Date("2020-03-01")
deltaT = 0.1 # timestep for projections 

# Specify scenarios regarding relaxation of interventions 
scales = c(1, 1.245, 1.755) # Scenarios for scaling of post-intervention beta
beta_noise_amplitude = 0.05 # amplitude for noise when scaling post-intervention beta 
intervention_lift_date <- as.Date("2020-06-01") # this is the date at which any relaxation of intervention begins
today = as.Date(Sys.Date()) # define today for adding noise to forward post-intervention transmission 

regional_aggregation = F # If true, do statewide estimates

```

Next, generate the simulation results as a .csv file
```{r}
# Output filepath 
output_path = "./forecast_20200518/"

# Run the simulation
source("inference_to_simulation.R")

```

Now, make the relevant plots: statewide
```{r}
regional_aggregation = T
output_path = "./forecast_20200518/" # where to access the result files 
plot_filename <- "4reg.outputs.png"
reg_hosp_cap = read.csv('idph_cluster_capacities.csv')
intervention_scenarios <- c("100", "10", "30")
state_hospital_capacity = 33742 # Total hospital beds in state
state_ICU_capacity = 3903
this_date <- "May 15, 2020" # Specify the last date of data used for inference
source("plot_intervention_comparisons.R")

regional_aggregation = F
source("plot_intervention_comparisons.R")

```

Calculate transmission reductions
```{r}
library(foreach)
# get mle
mle = read.csv('latest_fit_results/consolidated.all.sample_from_surface.csv') %>% arrange(desc(loglik))
mle = mle[1, ]

# Import contact matrix data
load(contact_filename)

print('Reading in population files')
# Make population a vector that has the regions concatenated together
population1 = read.csv(population_filename_1)
colnames(population1) <- c("AGE_GROUP_MIN", "POPULATION")
pop1 = sum(population1$POPULATION)

population2 = read.csv(population_filename_2)
colnames(population2) <- c("AGE_GROUP_MIN", "POPULATION")
pop2 = sum(population2$POPULATION)

population3 = read.csv(population_filename_3)
colnames(population3) <- c("AGE_GROUP_MIN", "POPULATION")
pop3 = sum(population3$POPULATION)

population4 = read.csv(population_filename_4)
colnames(population4) <- c("AGE_GROUP_MIN", "POPULATION")
pop4 = sum(population4$POPULATION)

# Calculate average transmission reduction
compartments = c('home','school','work','other')
foreach (i=1:length(compartments)) %do%{
    matrix(pomp_contacts[[compartments[i]]][1:81], nrow=9, ncol=9)
} -> contacts1 

foreach (i=1:length(compartments)) %do%{
    matrix(pomp_contacts[[compartments[i]]][82:162], nrow=9, ncol=9)
} -> contacts2 

foreach (i=1:length(compartments)) %do%{
    matrix(pomp_contacts[[compartments[i]]][163:243], nrow=9, ncol=9)
} -> contacts3

foreach (i=1:length(compartments)) %do%{
    matrix(pomp_contacts[[compartments[i]]][244:324], nrow=9, ncol=9)
} -> contacts4

get_dom_eigen = function(m, scalings = c(1,1,1,1)){
    compartments = c('home','school','work','other')
    base = matrix(0, ncol=9, nrow=9)
    for (i in seq(1:length(compartments))){
        base = base + m[[i]] * scalings[i]
    }
    Re(eigen(base)$values[1])
}

reduction1 = (get_dom_eigen(contacts1, c(1, 0, 0.6, 0.5)) * mle$beta2_1) * (pop1/sum(pop1, pop2, pop3, pop4))
reduction2 = (get_dom_eigen(contacts2, c(1, 0, 0.6, 0.5)) * mle$beta2_2) * (pop2/sum(pop1, pop2, pop3, pop4))
reduction3 = (get_dom_eigen(contacts3, c(1, 0, 0.6, 0.5)) * mle$beta2_3) * (pop3/sum(pop1, pop2, pop3, pop4))
reduction4 = (get_dom_eigen(contacts4, c(1, 0, 0.6, 0.5)) * mle$beta2_3) * (pop4/sum(pop1, pop2, pop3, pop4))

post_transmission = reduction1 + reduction2 + reduction3 + reduction4

reduction1 = (get_dom_eigen(contacts1) * mle$beta1) * (pop1/sum(pop1, pop2, pop3, pop4))
reduction2 = (get_dom_eigen(contacts2) * mle$beta1) * (pop2/sum(pop1, pop2, pop3, pop4))
reduction3 = (get_dom_eigen(contacts3) * mle$beta1) * (pop3/sum(pop1, pop2, pop3, pop4))
reduction4 = (get_dom_eigen(contacts4) * mle$beta1) * (pop4/sum(pop1, pop2, pop3, pop4))
pre_transmission = reduction1 + reduction2 + reduction3 + reduction4

difference = pre_transmission - post_transmission

for (s in seq(1.1, 2.5, 0.005)){
    reduction1 = (get_dom_eigen(contacts1, c(1, 0, 0.6, 0.5)) * mle$beta2_1 * s) * (pop1/sum(pop1, pop2, pop3, pop4))
    reduction2 = (get_dom_eigen(contacts2, c(1, 0, 0.6, 0.5)) * mle$beta2_2 * s) * (pop2/sum(pop1, pop2, pop3, pop4))
    reduction3 = (get_dom_eigen(contacts3, c(1, 0, 0.6, 0.5)) * mle$beta2_3 * s) * (pop3/sum(pop1, pop2, pop3, pop4))
    reduction4 = (get_dom_eigen(contacts4, c(1, 0, 0.6, 0.5)) * mle$beta2_4 * s) * (pop4/sum(pop1, pop2, pop3, pop4))

    post_transmission2 = reduction1 + reduction2 + reduction3 + reduction4
    if (post_transmission2 > (0.3 * difference + post_transmission)){
        print(post_transmission2)
        print(0.3 * difference + post_transmission)
        print(s)
        break
    }
}

print(1-post_transmission/pre_transmission)
```

